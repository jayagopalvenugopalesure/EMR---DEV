import org.apache.commons.io.IOUtils
import java.net.URL
import java.nio.charset.Charset

// Zeppelin creates and injects sc (SparkContext) and sqlContext (HiveContext or SqlContext)
// So you don't need create them manually

// load bank data
val bankText = sc.parallelize(
    IOUtils.toString(
        new URL("https://s3.amazonaws.com/apache-zeppelin/tutorial/bank/bank.csv"),
        Charset.forName("utf8")).split("\n"))

case class Bank(age: Integer, job: String, marital: String, education: String, balance: Integer, housing: String, loan: String, contact: String, day: Integer, month: String, y: String)

val bank = bankText.map(s => s.split(";")).filter(s => s(0) != "\"age\"").map(
    s => Bank(s(0).toInt, 
            s(1).replaceAll("\"", ""),
            s(2).replaceAll("\"", ""),
            s(3).replaceAll("\"", ""),
            s(5).replaceAll("\"", "").toInt,
            s(6).replaceAll("\"", ""),
            s(7).replaceAll("\"", ""),
            s(8).replaceAll("\"", ""),
            s(9).replaceAll("\"", "").toInt,
            s(10).replaceAll("\"", ""),
            s(16).replaceAll("\"", "")
        )
).toDF()

bank.registerTempTable("bank")
bank.write.format("json").mode("append").partitionBy("month").save("s3://esure-emr-dev-jayagopal/json_v2/")


Drop table Customer_dev_Partition;
create external table Customer_dev_Partition(
age int,
job string,
marital string,
education string,
balance int,
housing String,
loan String,
contact String,
day  int
)
PARTITIONED BY(month string, y STRING)
stored as parquet
LOCATION 's3://esure-emr-dev-jayagopal/partitionparquet2/';

MSCK REPAIR TABLE Customer_dev_Partition;

SET hive.exec.scratchdir=/tmp/hive/;
SET hive.exec.stagingdir=/tmp/hive/;

--Need this set commands 

INSERT OVERWRITE TABLE Customer_dev_Partition PARTITION (month, y) SELECT * from Customer_dev_Partition WHERE month = 'apr' and y = 'no';

***Needs to have the partition column in the were clause

spark.sql("SET hive.exec.scratchdir=/tmp/hive/;SET hive.exec.stagingdir=/tmp/hive/;SET hive.exec.dynamic.partition = true;SET hive.exec.dynamic.partition.mode = nonstrict;INSERT OVERWRITE TABLE Customer_dev_Partition PARTITION (month, y) SELECT * from Customer_dev_Partition WHERE month = 'jul' and y = 'no' and job not in ('services')"
